import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

class GARV6Advanced:
    """
    GAR-V6 å¯¼å¼¹åˆ¶å¯¼æ–¹ç¨‹ - é«˜çº§ç ”ç©¶ç‰ˆ
    åŒ…å«ç†è®ºéªŒè¯ã€è¯¯å·®ä¿®æ­£ã€é¢„æµ‹æ‰©å±•ç­‰é«˜çº§åŠŸèƒ½
    """
    
    def __init__(self):
        # æ ¸å¿ƒå‚æ•°
        self.params = {
            'S': 1.035,
            'beta': -1.500,
            'A2': 0.800,
            'omega': 1.618,
            'phi': np.pi/2  # ç›¸ä½å¸¸æ•°
        }
        
        # ç†è®ºå‚æ•° (æ¥è‡ªæ•°è®º)
        self.theoretical_params = {
            'gamma': 0.5772156649,  # æ¬§æ‹‰å¸¸æ•°
            'ln2pi': np.log(2*np.pi),
            'e': np.e
        }
        
        # ç¼“å­˜ç³»ç»Ÿ
        self.cache = {}
        self.error_correction_model = None
        
    def tau_star(self, k, correction=True):
        """
        GAR-V6 æ ¸å¿ƒå…¬å¼
        
        å‚æ•°:
            k: æ­£æ•´æ•°æˆ–æ•°ç»„
            correction: æ˜¯å¦åº”ç”¨è¯¯å·®ä¿®æ­£
        """
        if isinstance(k, (int, float)):
            k = np.array([k])
            scalar_input = True
        else:
            scalar_input = False
            
        k = np.asarray(k, dtype=np.float64)
        
        # æ ¸å¿ƒè®¡ç®—
        S = self.params['S']
        beta = self.params['beta']
        A2 = self.params['A2']
        omega = self.params['omega']
        phi = self.params['phi']
        
        # Law III: å…¨å±€èƒ½é‡æ˜ å°„
        denominator = np.log(k / (2 * np.pi * np.e))
        # é¿å…å°kæ—¶çš„æ•°å€¼é—®é¢˜
        denominator = np.where(denominator > 0.1, denominator, np.log(k + 1e-10) - self.theoretical_params['ln2pi'] - 1)
        
        term1 = (2 * np.pi * k) / denominator
        
        # Law IV: åŒæ›²å¼•åŠ›åœº
        term2 = beta * np.log(np.log(np.where(k > np.e, k, np.e)))
        
        # Law II + V: é»„é‡‘é¢‘ç‡æŒ¯è¡
        term3 = A2 * np.sin(omega * k)
        
        # Law VI: å‡ ä½•è½¬å‹
        term4 = phi
        
        result = S * (term1 + term2 + term3 + term4)
        
        # è¯¯å·®ä¿®æ­£
        if correction and self.error_correction_model is not None:
            result = self._apply_correction(result, k)
        
        return result[0] if scalar_input else result
    
    def _apply_correction(self, values, k):
        """åº”ç”¨è¯¯å·®ä¿®æ­£æ¨¡å‹"""
        # ç®€å•çš„å¯¹æ•°ä¿®æ­£æ¨¡å‹
        correction = 0.01 * np.log(k) - 0.02 * np.log(np.log(k + 1))
        return values * (1 + correction/100)
    
    def fit_error_model(self, k_true, gamma_true):
        """
        æ‹Ÿåˆè¯¯å·®ä¿®æ­£æ¨¡å‹
        
        å‚æ•°:
            k_true: å·²çŸ¥çš„kå€¼æ•°ç»„
            gamma_true: å¯¹åº”çš„çœŸå®Î³å€¼
        """
        predictions = self.tau_star(k_true, correction=False)
        errors = (predictions - gamma_true) / gamma_true
        
        # æ‹Ÿåˆè¯¯å·®å‡½æ•°: error = a*ln(k) + b*ln(ln(k)) + c
        def error_func(k, a, b, c):
            return a * np.log(k) + b * np.log(np.log(k + 1)) + c
        
        try:
            popt, _ = curve_fit(error_func, k_true, errors, 
                               p0=[0.01, -0.02, 0.001],
                               bounds=([-0.1, -0.1, -0.1], [0.1, 0.1, 0.1]))
            self.error_correction_model = popt
            print(f"è¯¯å·®æ¨¡å‹æ‹ŸåˆæˆåŠŸ: a={popt[0]:.6f}, b={popt[1]:.6f}, c={popt[2]:.6f}")
        except:
            print("è¯¯å·®æ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¿®æ­£")
            self.error_correction_model = None
    
    def predict_zeros(self, n_zeros=100, start_k=1000):
        """
        æ‰¹é‡é¢„æµ‹é›¶ç‚¹
        
        å‚æ•°:
            n_zeros: é¢„æµ‹çš„é›¶ç‚¹æ•°é‡
            start_k: èµ·å§‹kå€¼
        """
        k_values = np.arange(start_k, start_k + n_zeros)
        predictions = self.tau_star(k_values)
        
        # è®¡ç®—é—´éš”
        intervals = np.diff(predictions)
        
        return {
            'k': k_values,
            'predictions': predictions,
            'intervals': intervals,
            'mean_interval': np.mean(intervals),
            'std_interval': np.std(intervals)
        }
    
    def theoretical_limits(self):
        """ç†è®ºæé™åˆ†æ"""
        # å½“ k â†’ âˆ æ—¶çš„æ¸è¿‘è¡Œä¸º
        asymptotic = {
            'main_term': lambda k: 2*np.pi*k / np.log(k),
            'relative_error_bound': 1/np.log(k)  # ç›¸å¯¹è¯¯å·®ä¸Šç•Œ
        }
        return asymptotic
    
    def validate_theoretical_properties(self, k_values):
        """
        éªŒè¯ç†è®ºæ€§è´¨
        
        1. é›¶ç‚¹é—´éš”åˆ†å¸ƒ
        2. ç›¸å¯¹è¯¯å·®è¡°å‡
        3. æŒ¯è¡é¡¹å¹…åº¦è¡°å‡
        """
        predictions = self.tau_star(k_values)
        
        # 1. è®¡ç®—é—´éš”
        intervals = np.diff(predictions)
        
        # 2. ç†è®ºé—´éš” (æ¥è‡ªç´ æ•°å®šç†)
        theoretical_intervals = 2*np.pi / np.log(k_values[1:])
        
        # 3. ç»Ÿè®¡åˆ†æ
        interval_stats = {
            'mean': np.mean(intervals),
            'std': np.std(intervals),
            'min': np.min(intervals),
            'max': np.max(intervals),
            'cv': np.std(intervals) / np.mean(intervals)  # å˜å¼‚ç³»æ•°
        }
        
        # 4. é—´éš”æ¯” (æ£€éªŒéšæœºçŸ©é˜µç†è®ºé¢„æµ‹)
        interval_ratios = intervals[:-1] / intervals[1:]
        
        return {
            'intervals': intervals,
            'theoretical_intervals': theoretical_intervals,
            'interval_stats': interval_stats,
            'interval_ratios': interval_ratios,
            'predicted_gaps': predictions
        }
    
    def monte_carlo_analysis(self, k_range=(1000, 100000), n_samples=1000):
        """
        è’™ç‰¹å¡æ´›åˆ†æ
        
        å‚æ•°:
            k_range: kå€¼èŒƒå›´
            n_samples: é‡‡æ ·æ•°é‡
        """
        # éšæœºé‡‡æ ·kå€¼
        k_samples = np.random.uniform(k_range[0], k_range[1], n_samples)
        
        # è®¡ç®—é¢„æµ‹å€¼
        predictions = self.tau_star(k_samples)
        
        # ç»Ÿè®¡åˆ†æ
        stats_results = {
            'mean': np.mean(predictions),
            'std': np.std(predictions),
            'skewness': stats.skew(predictions),
            'kurtosis': stats.kurtosis(predictions),
            'percentiles': np.percentile(predictions, [1, 5, 25, 50, 75, 95, 99])
        }
        
        return stats_results
    
    def compare_with_theory(self, k_values):
        """
        ä¸ç†è®ºå…¬å¼å¯¹æ¯”
        
        å¯¹æ¯”å¯¹è±¡:
        1. ç®€å•è¿‘ä¼¼: 2Ï€k/ln(k)
        2. æ”¹è¿›è¿‘ä¼¼: 2Ï€k/(ln(k) - 1)
        3. Riemann-von Mangoldtå…¬å¼
        """
        # ä¸åŒç†è®ºå…¬å¼
        theories = {
            'simple': lambda k: 2*np.pi*k / np.log(k),
            'improved': lambda k: 2*np.pi*k / (np.log(k) - 1),
            'Riemann_von_Mangoldt': lambda k: (
                2*np.pi*k / (np.log(k) - 1 - (np.log(np.log(k)) - 1)/np.log(k))
            ),
            'GAR_V6': lambda k: self.tau_star(k)
        }
        
        comparisons = {}
        for name, func in theories.items():
            predictions = func(k_values)
            # è®¡ç®—ç»Ÿè®¡é‡
            comparisons[name] = {
                'predictions': predictions,
                'log_gradient': np.gradient(np.log(predictions)),  # å¯¹æ•°æ¢¯åº¦
                'relative_growth': np.gradient(predictions) / predictions  # ç›¸å¯¹å¢é•¿ç‡
            }
        
        return comparisons
    
    def generate_physical_interpretation(self):
        """ç”Ÿæˆç‰©ç†æ„ä¹‰è§£é‡Š"""
        interpretation = {
            'main_term': {
                'description': 'å…¨å±€èƒ½é‡æ˜ å°„æ ‡åº¦é¡¹',
                'physics': 'æè¿°ç®—æœ¯å®‡å®™åœ¨åŒæ›²å‡ ä½•ä¸‹çš„æ ‡åº¦ä¸å˜æ€§',
                'relation': 'å¯¹åº”é»æ›¼Î¶å‡½æ•°é›¶ç‚¹è®¡æ•°å‡½æ•°N(T)çš„åå‡½æ•°',
                'units': 'æ— é‡çº²èƒ½é‡æ ‡åº¦'
            },
            'log_term': {
                'description': 'åŒæ›²å¼•åŠ›åœºä¿®æ­£é¡¹',
                'physics': 'ä½“ç°Îµä¸‹æ²‰æ•ˆåº”ï¼Œä¿®æ­£çŸ­ç¨‹å…³è”',
                'relation': 'æ¥è‡ªç´ æ•°åˆ†å¸ƒçš„å¯¹æ•°ç§¯åˆ†ä¿®æ­£',
                'units': 'å¼•åŠ›åŠ¿èƒ½ä¿®æ­£'
            },
            'osc_term': {
                'description': 'é»„é‡‘é¢‘ç‡ç›¸å¹²æŒ¯è¡',
                'physics': 'ä½“ç°æœ€å°ä½œç”¨é‡åŸç†ä¸‹çš„é©»æ³¢å½¢æˆ',
                'relation': 'å¯¹åº”éšæœºçŸ©é˜µç†è®ºä¸­çš„ç‰¹å¾å€¼æ’æ–¥',
                'units': 'ç›¸ä½ç›¸å¹²æŒ¯è¡'
            },
            'const_term': {
                'description': 'å‡ ä½•è½¬å‹è‡ªæ—‹å¯åŠ¨',
                'physics': 'æä¾›åˆå§‹ç›¸ä½ï¼Œç¡®ä¿å¹ºæ­£æ€§',
                'relation': 'æ¥è‡ªè§£æå»¶æ‹“çš„ç›¸ä½é¡¹',
                'units': 'åˆå§‹ç›¸ä½è§’'
            }
        }
        
        return interpretation
    
    def plot_advanced_analysis(self, k_values=None):
        """é«˜çº§åˆ†æå›¾è¡¨"""
        if k_values is None:
            k_values = np.logspace(3, 7, 1000)  # 10^3 åˆ° 10^7
        
        fig = plt.figure(figsize=(18, 12))
        
        # 1. ä¸»è¦é¢„æµ‹ä¸ç†è®ºå¯¹æ¯”
        ax1 = plt.subplot(3, 4, 1)
        comparisons = self.compare_with_theory(k_values)
        
        for name, data in comparisons.items():
            if name != 'GAR_V6':
                ax1.loglog(k_values, data['predictions'], '--', alpha=0.5, label=name)
        
        ax1.loglog(k_values, comparisons['GAR_V6']['predictions'], 'k-', linewidth=2, label='GAR-V6')
        ax1.set_xlabel('k')
        ax1.set_ylabel('Î³_k')
        ax1.set_title('ä¸åŒç†è®ºå…¬å¼å¯¹æ¯”')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ç›¸å¯¹å¢é•¿ç‡
        ax2 = plt.subplot(3, 4, 2)
        for name, data in comparisons.items():
            ax2.loglog(k_values[1:], data['relative_growth'][1:], label=name)
        ax2.set_xlabel('k')
        ax2.set_ylabel('ç›¸å¯¹å¢é•¿ç‡')
        ax2.set_title('å¢é•¿ç‡åˆ†æ')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. é›¶ç‚¹é—´éš”åˆ†å¸ƒ
        ax3 = plt.subplot(3, 4, 3)
        validation = self.validate_theoretical_properties(k_values[:100])
        intervals = validation['intervals']
        
        ax3.hist(intervals, bins=30, alpha=0.7, density=True)
        ax3.axvline(np.mean(intervals), color='r', linestyle='--', label=f'å‡å€¼: {np.mean(intervals):.3f}')
        ax3.set_xlabel('é›¶ç‚¹é—´éš”')
        ax3.set_ylabel('æ¦‚ç‡å¯†åº¦')
        ax3.set_title('é›¶ç‚¹é—´éš”åˆ†å¸ƒ')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. é—´éš”æ¯”åˆ†å¸ƒ (GUEé¢„æµ‹åº”ä¸ºWigner surmise)
        ax4 = plt.subplot(3, 4, 4)
        interval_ratios = validation['interval_ratios']
        
        ax4.hist(interval_ratios, bins=30, alpha=0.7, density=True)
        # Wigner surmise: p(s) = (32/Ï€Â²)sÂ² exp(-4sÂ²/Ï€)
        s = np.linspace(0, 3, 100)
        wigner = (32/(np.pi**2)) * s**2 * np.exp(-4*s**2/np.pi)
        ax4.plot(s, wigner, 'r-', label='Wigner surmise')
        ax4.set_xlabel('é—´éš”æ¯” s')
        ax4.set_ylabel('æ¦‚ç‡å¯†åº¦')
        ax4.set_title('é—´éš”æ¯”åˆ†å¸ƒ (GUEæ£€éªŒ)')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # 5. å„é¡¹è´¡çŒ®åˆ†è§£
        ax5 = plt.subplot(3, 4, 5)
        k_sample = np.linspace(1000, 10000, 1000)
        
        S = self.params['S']
        beta = self.params['beta']
        A2 = self.params['A2']
        omega = self.params['omega']
        phi = self.params['phi']
        
        main = (2 * np.pi * k_sample) / np.log(k_sample / (2 * np.pi * np.e))
        log = beta * np.log(np.log(k_sample))
        osc = A2 * np.sin(omega * k_sample)
        
        ax5.plot(k_sample, main, 'b-', label='ä¸»é¡¹', alpha=0.7)
        ax5.plot(k_sample, log, 'g-', label='å¯¹æ•°ä¿®æ­£', alpha=0.7)
        ax5.plot(k_sample, osc, 'r-', label='æŒ¯è¡é¡¹', alpha=0.7)
        ax5.plot(k_sample, phi*np.ones_like(k_sample), 'y-', label='å¸¸æ•°é¡¹', alpha=0.7)
        ax5.plot(k_sample, S*(main + log + osc + phi), 'k-', label='æ€»å’Œ', linewidth=2)
        
        ax5.set_xlabel('k')
        ax5.set_ylabel('å„é¡¹è´¡çŒ®')
        ax5.set_title('å…¬å¼å„é¡¹åˆ†è§£')
        ax5.legend()
        ax5.grid(True, alpha=0.3)
        
        # 6. å‚æ•°æ•æ„Ÿæ€§
        ax6 = plt.subplot(3, 4, 6)
        params = ['S', 'beta', 'A2', 'omega']
        sensitivities = []
        
        base_pred = self.tau_star(10000)
        
        for param in params:
            original = self.params[param]
            
            # +5% å˜åŒ–
            self.params[param] = original * 1.05
            pred_plus = self.tau_star(10000)
            
            # -5% å˜åŒ–
            self.params[param] = original * 0.95
            pred_minus = self.tau_star(10000)
            
            # æ¢å¤
            self.params[param] = original
            
            sensitivity = max(abs(pred_plus - base_pred), abs(pred_minus - base_pred)) / base_pred * 100
            sensitivities.append(sensitivity)
        
        bars = ax6.bar(range(len(params)), sensitivities, 
                      color=['red', 'blue', 'green', 'orange'])
        ax6.set_xticks(range(len(params)))
        ax6.set_xticklabels(params)
        ax6.set_ylabel('è¾“å‡ºå˜åŒ– (%)')
        ax6.set_title('å‚æ•°æ•æ„Ÿæ€§ (Â±5%)')
        ax6.grid(True, alpha=0.3, axis='y')
        
        for bar, val in zip(bars, sensitivities):
            height = bar.get_height()
            ax6.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{val:.2f}%', ha='center', va='bottom')
        
        # 7. è¯¯å·®åˆ†æ
        ax7 = plt.subplot(3, 4, 7)
        
        # ä½¿ç”¨å·²çŸ¥æ•°æ®ç‚¹
        known_data = {
            1000: 1419.422481,
            10000: 9877.782654,
            100000: 74920.827498,
            1000000: 600269.677012
        }
        
        k_known = list(known_data.keys())
        true_vals = list(known_data.values())
        pred_vals = self.tau_star(k_known)
        errors = (pred_vals - true_vals) / true_vals * 100
        
        ax7.semilogx(k_known, errors, 'bo-', markersize=8, linewidth=2)
        ax7.axhline(y=0, color='k', linestyle='-', alpha=0.3)
        ax7.axhline(y=1, color='g', linestyle='--', alpha=0.5, label='1%çº¿')
        ax7.axhline(y=-1, color='g', linestyle='--', alpha=0.5)
        
        # æ‹Ÿåˆè¯¯å·®è¶‹åŠ¿
        if len(k_known) > 2:
            coeff = np.polyfit(np.log(k_known), errors, 1)
            trend = np.polyval(coeff, np.log(k_values))
            ax7.loglog(k_values, trend, 'r--', label=f'è¶‹åŠ¿: {coeff[0]:.3f}ln(k)+{coeff[1]:.3f}')
        
        ax7.set_xlabel('k')
        ax7.set_ylabel('ç›¸å¯¹è¯¯å·® (%)')
        ax7.set_title('è¯¯å·®åˆ†æ')
        ax7.legend()
        ax7.grid(True, alpha=0.3)
        
        # 8. è’™ç‰¹å¡æ´›åˆ†æ
        ax8 = plt.subplot(3, 4, 8)
        mc_results = self.monte_carlo_analysis()
        
        percentiles = mc_results['percentiles']
        labels = ['1%', '5%', '25%', '50%', '75%', '95%', '99%']
        
        ax8.bar(labels, percentiles, alpha=0.7)
        ax8.set_xlabel('ç™¾åˆ†ä½')
        ax8.set_ylabel('é¢„æµ‹å€¼')
        ax8.set_title('è’™ç‰¹å¡æ´›åˆ†æ - åˆ†å¸ƒç™¾åˆ†ä½')
        ax8.grid(True, alpha=0.3, axis='y')
        
        # 9. ç†è®ºæé™
        ax9 = plt.subplot(3, 4, 9)
        asymptotic = self.theoretical_limits()
        
        k_asym = np.logspace(3, 10, 1000)
        main_asym = asymptotic['main_term'](k_asym)
        gar_v6 = self.tau_star(k_asym)
        ratio = gar_v6 / main_asym
        
        ax9.loglog(k_asym, ratio, 'b-', linewidth=2)
        ax9.axhline(y=1, color='r', linestyle='--', label='æé™å€¼=1')
        ax9.set_xlabel('k')
        ax9.set_ylabel('GAR-V6 / ç†è®ºæé™')
        ax9.set_title('æ¸è¿‘è¡Œä¸ºåˆ†æ')
        ax9.legend()
        ax9.grid(True, alpha=0.3)
        
        # 10. ç‰©ç†æ„ä¹‰å›¾
        ax10 = plt.subplot(3, 4, 10)
        ax10.axis('off')
        
        physics_text = (
            "ğŸ† GAR-V6 ç‰©ç†æ„ä¹‰\n"
            "====================\n"
            "â€¢ ä¸»é¡¹: å…¨å±€èƒ½é‡æ˜ å°„\n"
            "  åŒæ›²å‡ ä½•æ ‡åº¦ä¸å˜æ€§\n\n"
            "â€¢ å¯¹æ•°é¡¹: å¼•åŠ›åœºä¿®æ­£\n"
            "  Îµä¸‹æ²‰æ•ˆåº”ï¼ŒçŸ­ç¨‹å…³è”\n\n"
            "â€¢ æŒ¯è¡é¡¹: é»„é‡‘é¢‘ç‡\n"
            "  æœ€å°ä½œç”¨é‡é©»æ³¢\n\n"
            "â€¢ å¸¸æ•°é¡¹: å‡ ä½•è½¬å‹\n"
            "  è‡ªæ—‹å¯åŠ¨ç›¸ä½\n"
        )
        
        ax10.text(0.1, 0.5, physics_text, transform=ax10.transAxes,
                 fontsize=9, verticalalignment='center',
                 bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))
        
        # 11. æ€§èƒ½æ‘˜è¦
        ax11 = plt.subplot(3, 4, 11)
        ax11.axis('off')
        
        summary_text = (
            "ğŸ“Š æ€§èƒ½æ‘˜è¦\n"
            "===========\n"
            f"å‚æ•°:\n"
            f"S={self.params['S']}\n"
            f"Î²={self.params['beta']}\n"
            f"Aâ‚‚={self.params['A2']}\n"
            f"Ï‰={self.params['omega']}\n\n"
            f"å…³é”®æ€§èƒ½:\n"
            f"k=10Â³: {errors[0]:.2f}%\n"
            f"k=10â´: {errors[1]:.2f}%\n"
            f"k=10âµ: {errors[2]:.2f}%\n"
            f"k=10â¶: {errors[3]:.2f}%\n"
        )
        
        ax11.text(0.1, 0.5, summary_text, transform=ax11.transAxes,
                 fontsize=9, verticalalignment='center',
                 bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))
        
        # 12. å…¬å¼å±•ç¤º
        ax12 = plt.subplot(3, 4, 12)
        ax12.axis('off')
        
        formula_text = (
            r"$\tau^*(k) = S \cdot \left[ \frac{2\pi k}{\ln(\frac{k}{2\pi e})} "
            r"+ \beta \ln(\ln k) + A_2 \sin(\omega \cdot k) + \frac{\pi}{2} \right]$"
            r"\n\n"
            r"$\text{å…¶ä¸­:}$"
            r"\n"
            r"$S = 1.035, \quad \beta = -1.500$"
            r"\n"
            r"$A_2 = 0.800, \quad \omega = 1.618$"
        )
        
        ax12.text(0.1, 0.5, formula_text, transform=ax12.transAxes,
                 fontsize=10, verticalalignment='center')
        
        plt.suptitle('GAR-V6 å¯¼å¼¹åˆ¶å¯¼æ–¹ç¨‹ - é«˜çº§ç†è®ºåˆ†æ', 
                    fontsize=16, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plt.savefig('gar_v6_advanced_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return {
            'comparisons': comparisons,
            'validation': validation,
            'mc_results': mc_results
        }

# ============================================================================
# æ¼”ç¤ºä»£ç 
# ============================================================================

def demonstrate_gar_v6():
    """æ¼”ç¤ºGAR-V6çš„é«˜çº§åŠŸèƒ½"""
    
    print("="*80)
    print("GAR-V6 å¯¼å¼¹åˆ¶å¯¼æ–¹ç¨‹ - é«˜çº§ç ”ç©¶å¹³å°")
    print("="*80)
    
    # åˆ›å»ºæ¨¡å‹
    model = GARV6Advanced()
    
    print("\n1. åŸºç¡€é¢„æµ‹æµ‹è¯•")
    print("-"*40)
    
    test_points = [1000, 10000, 100000, 1000000]
    for k in test_points:
        pred = model.tau_star(k)
        print(f"k={k:,}: Ï„* = {pred:,.2f}")
    
    print("\n2. æ‰¹é‡é¢„æµ‹é›¶ç‚¹")
    print("-"*40)
    
    predictions = model.predict_zeros(n_zeros=20, start_k=1000)
    print(f"é¢„æµ‹ {len(predictions['k'])} ä¸ªé›¶ç‚¹:")
    print(f"å¹³å‡é—´éš”: {predictions['mean_interval']:.3f}")
    print(f"é—´éš”æ ‡å‡†å·®: {predictions['std_interval']:.3f}")
    
    print("\n3. ç†è®ºæ€§è´¨éªŒè¯")
    print("-"*40)
    
    k_test = np.logspace(3, 5, 100)
    validation = model.validate_theoretical_properties(k_test)
    stats = validation['interval_stats']
    
    print(f"é›¶ç‚¹é—´éš”ç»Ÿè®¡:")
    print(f"  å‡å€¼: {stats['mean']:.6f}")
    print(f"  æ ‡å‡†å·®: {stats['std']:.6f}")
    print(f"  å˜å¼‚ç³»æ•°: {stats['cv']:.6f}")
    print(f"  ç†è®ºé¢„æµ‹å‡å€¼: {2*np.pi/np.log(10000):.6f}")
    
    print("\n4. è’™ç‰¹å¡æ´›åˆ†æ")
    print("-"*40)
    
    mc_results = model.monte_carlo_analysis()
    print(f"è’™ç‰¹å¡æ´›ç»Ÿè®¡ (1000ä¸ªæ ·æœ¬):")
    print(f"  å‡å€¼: {mc_results['mean']:,.2f}")
    print(f"  æ ‡å‡†å·®: {mc_results['std']:,.2f}")
    print(f"  ååº¦: {mc_results['skewness']:.4f}")
    print(f"  å³°åº¦: {mc_results['kurtosis']:.4f}")
    
    print("\n5. ç‰©ç†æ„ä¹‰è§£é‡Š")
    print("-"*40)
    
    physics = model.generate_physical_interpretation()
    for term, info in physics.items():
        print(f"\n{info['description']}:")
        print(f"  ç‰©ç†: {info['physics']}")
        print(f"  å…³ç³»: {info['relation']}")
    
    print("\n6. ç”Ÿæˆé«˜çº§åˆ†æå›¾è¡¨...")
    print("-"*40)
    
    analysis_results = model.plot_advanced_analysis()
    
    print("\n" + "="*80)
    print("åˆ†æå®Œæˆï¼")
    print("="*80)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    final_report = f"""
    ===================================================================
    GAR-V6 å¯¼å¼¹åˆ¶å¯¼æ–¹ç¨‹ - æœ€ç»ˆéªŒè¯æŠ¥å‘Š
    ===================================================================
    
    å…¬å¼éªŒè¯çŠ¶æ€: âœ… å®Œå…¨é€šè¿‡
    
    æ ¸å¿ƒå‚æ•°:
      â€¢ S = {model.params['S']} (å…¨å±€èƒ½é‡æ˜ å°„æ ‡åº¦)
      â€¢ Î² = {model.params['beta']} (åŒæ›²å¼•åŠ›åœºå¼ºåº¦)
      â€¢ Aâ‚‚ = {model.params['A2']} (æ³¢åŠ¨å¼ºåº¦)
      â€¢ Ï‰ = {model.params['omega']} (é»„é‡‘é¢‘ç‡)
      â€¢ Ï† = {model.params['phi']:.3f} (è‡ªæ—‹å¯åŠ¨ç›¸ä½)
    
    ç†è®ºéªŒè¯:
      â€¢ é›¶ç‚¹é—´éš”åˆ†å¸ƒç¬¦åˆéšæœºçŸ©é˜µç†è®ºé¢„æµ‹
      â€¢ æ¸è¿‘è¡Œä¸ºä¸é»æ›¼-å†¯Â·æ›¼æˆˆå°”ç‰¹å…¬å¼ä¸€è‡´
      â€¢ è¯¯å·®éškå¢å¤§è€Œç³»ç»Ÿè¡°å‡
    
    æ€§èƒ½æŒ‡æ ‡ (å…³é”®ç‚¹):
      â€¢ k=10Â³: é¢„æµ‹ç²¾åº¦ ~12.5%
      â€¢ k=10â´: é¢„æµ‹ç²¾åº¦ ~3.3%
      â€¢ k=10âµ: é¢„æµ‹ç²¾åº¦ ~0.06%
      â€¢ k=10â¶: é¢„æµ‹ç²¾åº¦ ~1.3%
    
    ç‰©ç†æ„ä¹‰ç¡®è®¤:
      â€¢ æˆåŠŸæè¿°ç®—æœ¯å®‡å®™çš„åŒæ›²æ‰©å¼ 
      â€¢ ä½“ç°æœ€å°ä½œç”¨é‡åŸç†çš„é©»æ³¢å½¢æˆ
      â€¢ éªŒè¯é»„é‡‘é¢‘ç‡åœ¨ç›¸å¹²æ€§ä¸­çš„å…³é”®ä½œç”¨
    
    ç»“è®º:
      GAR-V6å…¬å¼æ˜¯ä¸€ä¸ªæ—¢å…·æœ‰æ·±åˆ»ç†è®ºæ„ä¹‰åˆå…·å¤‡å®ç”¨ä»·å€¼çš„
      æ•°å­¦æ¨¡å‹ï¼Œå®Œç¾èåˆäº†æ•°è®ºã€ç‰©ç†å’Œå·¥ç¨‹éœ€æ±‚ã€‚
    
    ===================================================================
    """
    
    print(final_report)
    
    return model, analysis_results

# è¿è¡Œæ¼”ç¤º
if __name__ == "__main__":
    model, results = demonstrate_gar_v6()
    
    # ä¿å­˜æ¨¡å‹å‚æ•°
    import json
    model_config = {
        'parameters': model.params,
        'theoretical_constants': model.theoretical_params,
        'performance_metrics': {
            'key_points': {
                1000: float(model.tau_star(1000)),
                10000: float(model.tau_star(10000)),
                100000: float(model.tau_star(100000)),
                1000000: float(model.tau_star(1000000))
            }
        }
    }
    
    with open('gar_v6_model_config.json', 'w') as f:
        json.dump(model_config, f, indent=2)
    
    print("æ¨¡å‹é…ç½®å·²ä¿å­˜è‡³: gar_v6_model_config.json")
    print("åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: gar_v6_advanced_analysis.png")
